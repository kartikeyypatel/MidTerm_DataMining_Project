{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Mining Mid-Term Project : Kartikey Patel (kp888)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import itertools\n",
    "import time\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori, association_rules, fpgrowth\n",
    "import pandas as pd\n",
    "from brute_force_module import brute_force, print_frequent_itemsets, print_rules # Using the brute_force_module code to run the brute force method code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating csv files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No need to run if csv files are downloaded already"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'amazon.csv' has been created.\n"
     ]
    }
   ],
   "source": [
    "#Amazon Transactions\n",
    "data = [\n",
    "    {\"Transaction ID\": \"Trans1\", \"Books\": \"A Beginner's Guide, Java: The Complete Reference, Java For Dummies, Android Programming: The Big Nerd Ranch\"},\n",
    "    {\"Transaction ID\": \"Trans2\", \"Books\": \"A Beginner's Guide, Java: The Complete Reference, Java For Dummies\"},\n",
    "    {\"Transaction ID\": \"Trans3\", \"Books\": \"A Beginner's Guide, Java: The Complete Reference, Java For Dummies, Android Programming: The Big Nerd Ranch, Head First Java 2nd Edition\"},\n",
    "    {\"Transaction ID\": \"Trans4\", \"Books\": \"Android Programming: The Big Nerd Ranch, Head First Java 2nd Edition, Beginning Programming with Java\"},\n",
    "    {\"Transaction ID\": \"Trans5\", \"Books\": \"Android Programming: The Big Nerd Ranch, Beginning Programming with Java, Java 8 Pocket Guide\"},\n",
    "    {\"Transaction ID\": \"Trans6\", \"Books\": \"A Beginner's Guide, Android Programming: The Big Nerd Ranch, Head First Java 2nd Edition\"},\n",
    "    {\"Transaction ID\": \"Trans7\", \"Books\": \"A Beginner's Guide, Head First Java 2nd Edition, Beginning Programming with Java\"},\n",
    "    {\"Transaction ID\": \"Trans8\", \"Books\": \"Java: The Complete Reference, Java For Dummies, Android Programming: The Big Nerd Ranch\"},\n",
    "    {\"Transaction ID\": \"Trans9\", \"Books\": \"Java For Dummies, Android Programming: The Big Nerd Ranch, Head First Java 2nd Edition, Beginning Programming with Java\"},\n",
    "    {\"Transaction ID\": \"Trans10\", \"Books\": \"Beginning Programming with Java, Java 8 Pocket Guide, C++ Programming in Easy Steps\"},\n",
    "    {\"Transaction ID\": \"Trans11\", \"Books\": \"A Beginner's Guide, Java: The Complete Reference, Java For Dummies, Android Programming: The Big Nerd Ranch\"},\n",
    "    {\"Transaction ID\": \"Trans12\", \"Books\": \"A Beginner's Guide, Java: The Complete Reference, Java For Dummies, HTML and CSS: Design and Build Websites\"},\n",
    "    {\"Transaction ID\": \"Trans13\", \"Books\": \"A Beginner's Guide, Java: The Complete Reference, Java For Dummies, Java 8 Pocket Guide, HTML and CSS: Design and Build Websites\"},\n",
    "    {\"Transaction ID\": \"Trans14\", \"Books\": \"Java For Dummies, Android Programming: The Big Nerd Ranch, Head First Java 2nd Edition\"},\n",
    "    {\"Transaction ID\": \"Trans15\", \"Books\": \"Java For Dummies, Android Programming: The Big Nerd Ranch\"},\n",
    "    {\"Transaction ID\": \"Trans16\", \"Books\": \"A Beginner's Guide, Java: The Complete Reference, Java For Dummies, Android Programming: The Big Nerd Ranch\"},\n",
    "    {\"Transaction ID\": \"Trans17\", \"Books\": \"A Beginner's Guide, Java: The Complete Reference, Java For Dummies, Android Programming: The Big Nerd Ranch\"},\n",
    "    {\"Transaction ID\": \"Trans18\", \"Books\": \"Head First Java 2nd Edition, Beginning Programming with Java, Java 8 Pocket Guide\"},\n",
    "    {\"Transaction ID\": \"Trans19\", \"Books\": \"Android Programming: The Big Nerd Ranch, Head First Java 2nd Edition\"},\n",
    "    {\"Transaction ID\": \"Trans20\", \"Books\": \"A Beginner's Guide, Java: The Complete Reference, Java For Dummies\"}\n",
    "]\n",
    "\n",
    "# Define the CSV file path\n",
    "csv_file = \"amazon.csv\"\n",
    "\n",
    "# Write the data to the CSV file\n",
    "with open(csv_file, mode='w', newline='') as file:\n",
    "    fieldnames = ['Transaction ID', 'Books']\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "\n",
    "    writer.writeheader()\n",
    "    for row in data:\n",
    "        writer.writerow(row)\n",
    "\n",
    "print(f\"CSV file '{csv_file}' has been created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'BestBuy.csv' for BestBuy Transactions has been created.\n"
     ]
    }
   ],
   "source": [
    "#BestBuy Transactions\n",
    "data1 = [\n",
    "    {\"Transaction ID\": \"Trans1\", \"Items\": \"Desk Top, Printer, Flash Drive, Microsoft Office, Speakers, Anti-Virus\"},\n",
    "    {\"Transaction ID\": \"Trans2\", \"Items\": \"Lab Top, Flash Drive, Microsoft Office, Lab Top Case, Anti-Virus\"},\n",
    "    {\"Transaction ID\": \"Trans3\", \"Items\": \"Lab Top, Printer, Flash Drive, Microsoft Office, Anti-Virus, Lab Top Case, External Hard-Drive\"},\n",
    "    {\"Transaction ID\": \"Trans4\", \"Items\": \"Lab Top, Printer, Flash Drive, Anti-Virus, External Hard-Drive, Lab Top Case\"},\n",
    "    {\"Transaction ID\": \"Trans5\", \"Items\": \"Lab Top, Flash Drive, Lab Top Case, Anti-Virus\"},\n",
    "    {\"Transaction ID\": \"Trans6\", \"Items\": \"Lab Top, Printer, Flash Drive, Microsoft Office\"},\n",
    "    {\"Transaction ID\": \"Trans7\", \"Items\": \"Desk Top, Printer, Flash Drive, Microsoft Office\"},\n",
    "    {\"Transaction ID\": \"Trans8\", \"Items\": \"Lab Top, External Hard-Drive, Anti-Virus\"},\n",
    "    {\"Transaction ID\": \"Trans9\", \"Items\": \"Desk Top, Printer, Flash Drive, Microsoft Office, Lab Top Case, Anti-Virus, Speakers, External Hard-Drive\"},\n",
    "    {\"Transaction ID\": \"Trans10\", \"Items\": \"Digital Camera, Lab Top, Desk Top, Printer, Flash Drive, Microsoft Office, Lab Top Case, Anti-Virus, External Hard-Drive, Speakers\"},\n",
    "    {\"Transaction ID\": \"Trans11\", \"Items\": \"Lab Top, Desk Top, Lab Top Case, External Hard-Drive, Speakers, Anti-Virus\"},\n",
    "    {\"Transaction ID\": \"Trans12\", \"Items\": \"Digital Camera, Lab Top, Lab Top Case, External Hard-Drive, Anti-Virus, Speakers\"},\n",
    "    {\"Transaction ID\": \"Trans13\", \"Items\": \"Digital Camera, Speakers\"},\n",
    "    {\"Transaction ID\": \"Trans14\", \"Items\": \"Digital Camera, Desk Top, Printer, Flash Drive, Microsoft Office\"},\n",
    "    {\"Transaction ID\": \"Trans15\", \"Items\": \"Printer, Flash Drive, Microsoft Office, Anti-Virus, Lab Top Case, Speakers, External Hard-Drive\"},\n",
    "    {\"Transaction ID\": \"Trans16\", \"Items\": \"Digital Camera, Flash Drive, Microsoft Office, Anti-Virus, Lab Top Case, External Hard-Drive, Speakers\"},\n",
    "    {\"Transaction ID\": \"Trans17\", \"Items\": \"Digital Camera, Lab Top, Lab Top Case\"},\n",
    "    {\"Transaction ID\": \"Trans18\", \"Items\": \"Digital Camera, Lab Top Case, Speakers\"},\n",
    "    {\"Transaction ID\": \"Trans19\", \"Items\": \"Digital Camera, Lab Top, Printer, Flash Drive, Microsoft Office, Speakers, Lab Top Case, Anti-Virus\"},\n",
    "    {\"Transaction ID\": \"Trans20\", \"Items\": \"Digital Camera, Lab Top, Speakers, Anti-Virus, Lab Top Case\"}\n",
    "]\n",
    "\n",
    "# Define the CSV file path for Transaction Type 1\n",
    "csv_file1 = \"BestBuy.csv\"\n",
    "\n",
    "# Write the data to the CSV file for Transaction Type 1\n",
    "with open(csv_file1, mode='w', newline='') as file1:\n",
    "    fieldnames1 = ['Transaction ID', 'Items']\n",
    "    writer1 = csv.DictWriter(file1, fieldnames=fieldnames1)\n",
    "\n",
    "    writer1.writeheader()\n",
    "    for row1 in data1:\n",
    "        writer1.writerow(row1)\n",
    "\n",
    "print(f\"CSV file '{csv_file1}' for BestBuy Transactions has been created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'Kmart.csv' for Kmart Transactions has been created.\n"
     ]
    }
   ],
   "source": [
    "#Kmart Transactions\n",
    "\n",
    "data2 = [\n",
    "    {\"Transaction ID\": \"Trans1\", \"Items\": \"Decorative Pillows, Quilts, Embroidered Bedspread\"},\n",
    "    {\"Transaction ID\": \"Trans2\", \"Items\": \"Embroidered Bedspread, Shams, Kids Bedding, Bedding Collections, Bed Skirts, Bedspreads, Sheets\"},\n",
    "    {\"Transaction ID\": \"Trans3\", \"Items\": \"Decorative Pillows, Quilts, Embroidered Bedspread, Shams, Kids Bedding, Bedding Collections\"},\n",
    "    {\"Transaction ID\": \"Trans4\", \"Items\": \"Kids Bedding, Bedding Collections, Sheets, Bedspreads, Bed Skirts\"},\n",
    "    {\"Transaction ID\": \"Trans5\", \"Items\": \"Decorative Pillows, Kids Bedding, Bedding Collections, Sheets, Bed Skirts, Bedspreads\"},\n",
    "    {\"Transaction ID\": \"Trans6\", \"Items\": \"Bedding Collections, Bedspreads, Bed Skirts, Sheets, Shams, Kids Bedding\"},\n",
    "    {\"Transaction ID\": \"Trans7\", \"Items\": \"Decorative Pillows, Quilts\"},\n",
    "    {\"Transaction ID\": \"Trans8\", \"Items\": \"Decorative Pillows, Quilts, Embroidered Bedspread\"},\n",
    "    {\"Transaction ID\": \"Trans9\", \"Items\": \"Bedspreads, Bed Skirts, Shams, Kids Bedding, Sheets\"},\n",
    "    {\"Transaction ID\": \"Trans10\", \"Items\": \"Quilts, Embroidered Bedspread, Bedding Collections\"},\n",
    "    {\"Transaction ID\": \"Trans11\", \"Items\": \"Bedding Collections, Bedspreads, Bed Skirts, Kids Bedding, Shams, Sheets\"},\n",
    "    {\"Transaction ID\": \"Trans12\", \"Items\": \"Decorative Pillows, Quilts\"},\n",
    "    {\"Transaction ID\": \"Trans13\", \"Items\": \"Embroidered Bedspread, Shams\"},\n",
    "    {\"Transaction ID\": \"Trans14\", \"Items\": \"Sheets, Shams, Bed Skirts, Kids Bedding\"},\n",
    "    {\"Transaction ID\": \"Trans15\", \"Items\": \"Decorative Pillows, Quilts\"},\n",
    "    {\"Transaction ID\": \"Trans16\", \"Items\": \"Decorative Pillows, Kids Bedding, Bed Skirts, Shams\"},\n",
    "    {\"Transaction ID\": \"Trans17\", \"Items\": \"Decorative Pillows, Shams, Bed Skirts\"},\n",
    "    {\"Transaction ID\": \"Trans18\", \"Items\": \"Quilts, Sheets, Kids Bedding\"},\n",
    "    {\"Transaction ID\": \"Trans19\", \"Items\": \"Shams, Bed Skirts, Kids Bedding, Sheets\"},\n",
    "    {\"Transaction ID\": \"Trans20\", \"Items\": \"Decorative Pillows, Bedspreads, Shams, Sheets, Bed Skirts, Kids Bedding\"}\n",
    "]\n",
    "\n",
    "# Define the CSV file path for Transaction Type 2\n",
    "csv_file2 = \"Kmart.csv\"\n",
    "\n",
    "# Write the data to the CSV file for Transaction Type 2\n",
    "with open(csv_file2, mode='w', newline='') as file2:\n",
    "    fieldnames2 = ['Transaction ID', 'Items']\n",
    "    writer2 = csv.DictWriter(file2, fieldnames=fieldnames2)\n",
    "\n",
    "    writer2.writeheader()\n",
    "    for row2 in data2:\n",
    "        writer2.writerow(row2)\n",
    "\n",
    "print(f\"CSV file '{csv_file2}' for Kmart Transactions has been created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'nike.csv' for nike Transaction has been created.\n"
     ]
    }
   ],
   "source": [
    "#nike transactions\n",
    "\n",
    "data3 = [\n",
    "    {\"Transaction ID\": \"Trans1\", \"Items\": \"Running Shoe, Socks, Sweatshirts, Modern Pants\"},\n",
    "    {\"Transaction ID\": \"Trans2\", \"Items\": \"Running Shoe, Socks, Sweatshirts\"},\n",
    "    {\"Transaction ID\": \"Trans3\", \"Items\": \"Running Shoe, Socks, Sweatshirts, Modern Pants\"},\n",
    "    {\"Transaction ID\": \"Trans4\", \"Items\": \"Running Shoe, Sweatshirts, Modern Pants\"},\n",
    "    {\"Transaction ID\": \"Trans5\", \"Items\": \"Running Shoe, Socks, Sweatshirts, Modern Pants, Soccer Shoe\"},\n",
    "    {\"Transaction ID\": \"Trans6\", \"Items\": \"Running Shoe, Socks, Sweatshirts\"},\n",
    "    {\"Transaction ID\": \"Trans7\", \"Items\": \"Running Shoe, Socks, Sweatshirts, Modern Pants, Tech Pants, Rash Guard, Hoodies\"},\n",
    "    {\"Transaction ID\": \"Trans8\", \"Items\": \"Swimming Shirt, Socks, Sweatshirts\"},\n",
    "    {\"Transaction ID\": \"Trans9\", \"Items\": \"Swimming Shirt, Rash Guard, Dry Fit V-Nick, Hoodies, Tech Pants\"},\n",
    "    {\"Transaction ID\": \"Trans10\", \"Items\": \"Swimming Shirt, Rash Guard, Dry\"},\n",
    "    {\"Transaction ID\": \"Trans11\", \"Items\": \"Swimming Shirt, Rash Guard, Dry Fit V-Nick\"},\n",
    "    {\"Transaction ID\": \"Trans12\", \"Items\": \"Running Shoe, Swimming Shirt, Socks, Sweatshirts, Modern Pants, Soccer Shoe, Rash Guard, Hoodies, Tech Pants, Dry Fit V-Nick\"},\n",
    "    {\"Transaction ID\": \"Trans13\", \"Items\": \"Running Shoe, Swimming Shirt, Socks, Sweatshirts, Modern Pants, Soccer Shoe, Rash Guard, Tech Pants, Dry Fit V-Nick, Hoodies\"},\n",
    "    {\"Transaction ID\": \"Trans14\", \"Items\": \"Running Shoe, Swimming Shirt, Rash Guard, Tech Pants, Hoodies, Dry Fit V-Nick\"},\n",
    "    {\"Transaction ID\": \"Trans15\", \"Items\": \"Running Shoe, Swimming Shirt, Socks, Sweatshirts, Modern Pants, Dry Fit V-Nick, Rash Guard, Tech Pants\"},\n",
    "    {\"Transaction ID\": \"Trans16\", \"Items\": \"Swimming Shirt, Soccer Shoe, Hoodies, Dry Fit V-Nick, Tech Pants, Rash Guard\"},\n",
    "    {\"Transaction ID\": \"Trans17\", \"Items\": \"Running Shoe, Socks\"},\n",
    "    {\"Transaction ID\": \"Trans18\", \"Items\": \"Socks, Sweatshirts, Modern Pants, Soccer Shoe, Hoodies, Rash Guard, Tech Pants, Dry Fit V-Nick\"},\n",
    "    {\"Transaction ID\": \"Trans19\", \"Items\": \"Running Shoe, Swimming Shirt, Rash Guard\"},\n",
    "    {\"Transaction ID\": \"Trans20\", \"Items\": \"Running Shoe, Swimming Shirt, Socks, Sweatshirts, Modern Pants, Soccer Shoe, Hoodies, Tech Pants, Rash Guard, Dry Fit V-Nick\"}\n",
    "]\n",
    "\n",
    "# Define the CSV file path for Transaction Type 3\n",
    "csv_file3 = \"nike.csv\"\n",
    "\n",
    "# Write the data to the CSV file for Transaction Type 3\n",
    "with open(csv_file3, mode='w', newline='') as file3:\n",
    "    fieldnames3 = ['Transaction ID', 'Items']\n",
    "    writer3 = csv.DictWriter(file3, fieldnames=fieldnames3)\n",
    "\n",
    "    writer3.writeheader()\n",
    "    for row3 in data3:\n",
    "        writer3.writerow(row3)\n",
    "\n",
    "print(f\"CSV file '{csv_file3}' for nike Transaction has been created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'Generic.csv' for Generic Transaction has been created.\n"
     ]
    }
   ],
   "source": [
    "# Generic Transactions\n",
    "data4 = [\n",
    "    {\"Transaction ID\": \"Trans1\", \"Items\": \"A, B, C\"},\n",
    "    {\"Transaction ID\": \"Trans2\", \"Items\": \"A, B, C\"},\n",
    "    {\"Transaction ID\": \"Trans3\", \"Items\": \"A, B, C, D\"},\n",
    "    {\"Transaction ID\": \"Trans4\", \"Items\": \"A, B, C, D, E\"},\n",
    "    {\"Transaction ID\": \"Trans5\", \"Items\": \"A, B, D, E\"},\n",
    "    {\"Transaction ID\": \"Trans6\", \"Items\": \"A, D, E\"},\n",
    "    {\"Transaction ID\": \"Trans7\", \"Items\": \"A, E\"},\n",
    "    {\"Transaction ID\": \"Trans8\", \"Items\": \"A, E\"},\n",
    "    {\"Transaction ID\": \"Trans9\", \"Items\": \"A, C, E\"},\n",
    "    {\"Transaction ID\": \"Trans10\", \"Items\": \"A, C, E\"},\n",
    "    {\"Transaction ID\": \"Trans11\", \"Items\": \"A, C, E\"}\n",
    "]\n",
    "\n",
    "# Define the CSV file path for Transaction Type 4\n",
    "csv_file4 = \"Generic.csv\"\n",
    "\n",
    "# Write the data to the CSV file for Transaction Type 4\n",
    "with open(csv_file4, mode='w', newline='') as file4:\n",
    "    fieldnames4 = ['Transaction ID', 'Items']\n",
    "    writer4 = csv.DictWriter(file4, fieldnames=fieldnames4)\n",
    "\n",
    "    writer4.writeheader()\n",
    "    for row4 in data4:\n",
    "        writer4.writerow(row4)\n",
    "\n",
    "print(f\"CSV file '{csv_file4}' for Generic Transaction has been created.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "    transactions = []\n",
    "    with open(filename, 'r') as file:\n",
    "        csv_reader = csv.reader(file)\n",
    "        next(csv_reader)  # Skip header row\n",
    "        for row in csv_reader:\n",
    "            transactions.append(row[1].split(\", \"))\n",
    "    return transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of Apriori and FPGrowth Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_apriori_fpgrowth(transactions, min_support, min_confidence):\n",
    "    te = TransactionEncoder()\n",
    "    te_ary = te.fit(transactions).transform(transactions)\n",
    "    df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "    #Apriori\n",
    "    \n",
    "    start_time = time.time()\n",
    "    frequent_itemsets_apriori = apriori(df, min_support=min_support, use_colnames=True)\n",
    "    rules_apriori = association_rules(frequent_itemsets_apriori, metric=\"confidence\", min_threshold=min_confidence)\n",
    "    end_time = time.time()\n",
    "    print(f\"Apriori Execution Time: {end_time - start_time} seconds \\n\")\n",
    "    print(\"Apriori Frequent Itemsets\")\n",
    "    print(frequent_itemsets_apriori, \"\\n\")\n",
    "    if not rules_apriori.empty:\n",
    "        print(\"Apriori Association Rules : \")\n",
    "        # Convert antecedents and consequents to strings without square brackets\n",
    "        rules_apriori['antecedents'] = rules_apriori['antecedents'].apply(lambda x: ', '.join(x))\n",
    "        rules_apriori['consequents'] = rules_apriori['consequents'].apply(lambda x: ', '.join(x))\n",
    "        print(rules_apriori[['antecedents', 'consequents', 'support', 'confidence']].head(10).to_string(index=False))\n",
    "    else:\n",
    "        print(\"No association rules found.\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "    # FP-Growth\n",
    "    \n",
    "    start_time = time.time()\n",
    "    frequent_itemsets_fp = fpgrowth(df, min_support=min_support, use_colnames=True)\n",
    "    rules_fp = association_rules(frequent_itemsets_fp, metric=\"confidence\", min_threshold=min_confidence)\n",
    "    end_time = time.time()\n",
    "    print(f\"FP-Growth Execution Time: {end_time - start_time} seconds \\n\")\n",
    "    print(\"FP-Growth Frequent Itemsets\")\n",
    "    print(frequent_itemsets_fp, \"\\n\")\n",
    "    if not rules_fp.empty:\n",
    "        print(\"FP-Growth Association Rules : \")\n",
    "        # Convert antecedents and consequents to strings without square brackets\n",
    "        rules_fp['antecedents'] = rules_fp['antecedents'].apply(lambda x: ', '.join(x))\n",
    "        rules_fp['consequents'] = rules_fp['consequents'].apply(lambda x: ', '.join(x))\n",
    "        print(rules_fp[['antecedents', 'consequents', 'support', 'confidence']].head(10).to_string(index=False))\n",
    "    else:\n",
    "        print(\"No association rules found.\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Function to run the algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Brute Force Execution Time: 0.0 seconds \n",
      "\n",
      "Brute Force Frequent Itemsets:\n",
      "itemsets  support\n",
      "       C 0.636364\n",
      "       A 1.000000\n",
      "       E 0.727273\n",
      "    C, A 0.636364\n",
      "    E, A 0.727273\n",
      "\n",
      "\n",
      "Brute Force Association Rules:\n",
      "antecedents consequents  support  confidence\n",
      "          C           A 0.636364    1.000000\n",
      "          A           C 0.636364    0.636364\n",
      "          A           E 0.727273    0.727273\n",
      "          E           A 0.727273    1.000000\n",
      "\n",
      "\n",
      "Apriori Execution Time: 0.002692699432373047 seconds \n",
      "\n",
      "Apriori Frequent Itemsets\n",
      "   support itemsets\n",
      "0 1.000000      (A)\n",
      "1 0.636364      (C)\n",
      "2 0.727273      (E)\n",
      "3 0.636364   (C, A)\n",
      "4 0.727273   (E, A) \n",
      "\n",
      "Apriori Association Rules : \n",
      "antecedents consequents  support  confidence\n",
      "          C           A 0.636364    1.000000\n",
      "          A           C 0.636364    0.636364\n",
      "          E           A 0.727273    1.000000\n",
      "          A           E 0.727273    0.727273\n",
      "\n",
      "\n",
      "FP-Growth Execution Time: 0.0 seconds \n",
      "\n",
      "FP-Growth Frequent Itemsets\n",
      "   support itemsets\n",
      "0 1.000000      (A)\n",
      "1 0.636364      (C)\n",
      "2 0.727273      (E)\n",
      "3 0.636364   (C, A)\n",
      "4 0.727273   (E, A) \n",
      "\n",
      "FP-Growth Association Rules : \n",
      "antecedents consequents  support  confidence\n",
      "          C           A 0.636364    1.000000\n",
      "          A           C 0.636364    0.636364\n",
      "          E           A 0.727273    1.000000\n",
      "          A           E 0.727273    0.727273\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    datasets = [\"amazon.csv\", \"BestBuy.csv\", \"Kmart.csv\", \"nike.csv\", \"Generic.csv\"]\n",
    "    dataset_choice = int(input(\"Choose a dataset (1-5): \\n1.Amazon\\n2.BestBuy\\n3.Kmart\\n4.Nike\\n5.Generic\\n\"))\n",
    "    min_support = float(input(\"Enter minimum support (as a decimal): \"))\n",
    "    min_confidence = float(input(\"Enter minimum confidence (as a decimal): \"))\n",
    "\n",
    "    transactions = read_data(datasets[dataset_choice - 1])\n",
    "\n",
    "    # Brute Force\n",
    "    start_time = time.time()\n",
    "    frequent_itemsets, rules = brute_force(transactions, min_support, min_confidence)\n",
    "    end_time = time.time()\n",
    "    print(f\"\\nBrute Force Execution Time: {end_time - start_time} seconds \\n\")\n",
    "    print_frequent_itemsets(frequent_itemsets, method=\"Brute Force\")\n",
    "    print_rules(rules, method=\"Brute Force\")\n",
    "\n",
    "\n",
    "    # Apriori and FP-Growth\n",
    "    run_apriori_fpgrowth(transactions, min_support, min_confidence)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
